# 책의 첫 문장으로 발행년도와 장르 예측하기

**학번:** 20901
**이름:** 경승민

---

## 1. 문제 정의

### 프로젝트 목표
책의 첫 문장만을 보고 해당 책의 **발행년도**와 **장르**를 예측하는 지도 학습 모델을 개발합니다.

### 해결하고자 하는 문제
- 텍스트 데이터(책의 첫 문장)로부터 두 가지 타겟 변수를 동시에 예측
  - **장르 예측**: 다중 분류 문제 (20개 장르)
  - **년도 예측**: 회귀 문제 (1870년~2023년)

### 성능 목표
- 전체 평균 정확도 **60% 이상** 달성

---

## 2. 데이터 탐색 및 전처리

### 데이터 탐색 정보 및 통계

#### 데이터셋 개요
- **총 데이터 수**: 4,753개
- **속성**: 3개 (Year, Genre, Sentence)
- **데이터 타입**:
  - Year: 정수형 (int64)
  - Genre: 범주형 (object)
  - Sentence: 텍스트형 (object)

#### 장르 분포
| 장르 | 개수 |
|------|------|
| Novels | 1,079 |
| Non-Fiction | 647 |
| "Sex" | 525 |
| "Race" | 439 |
| Crime/Detective & Suspense/Thrillers | 398 |
| History & Historical Fiction | 309 |
| Memoirs & Autobiographies | 288 |
| 기타 | 1,068 |

**총 20개 장르**로 구성되어 있습니다.

#### 년도 분포
- **최소 년도**: 1870년
- **최대 년도**: 2023년
- **범위**: 약 153년

#### 문장 길이 통계
- **평균 문장 길이**: 약 200~400자
- **최소 길이**: 수십 자
- **최대 길이**: 수백 자

### 데이터 전처리 내용

1. **결측치 처리**
   - 결측치가 있는 행 제거 (`dropna()` 사용)
   - 전처리 후 완전한 데이터만 사용

2. **텍스트 벡터화**
   - **TF-IDF (Term Frequency-Inverse Document Frequency)** 방식 사용
   - `sklearn.feature_extraction.text.TfidfVectorizer` 사용
   - 상위 1,000개 단어만 추출하여 특성으로 사용
   - 영어 불용어(stop words) 제거
   - 텍스트를 1,000차원의 수치 벡터로 변환

3. **레이블 인코딩**
   - **장르**: `LabelEncoder`로 20개 장르를 0~19 정수로 변환
   - **년도**: 그대로 사용 (이미 수치형)

4. **데이터 분리**
   - 훈련 데이터: 70%
   - 테스트 데이터: 30%
   - `train_test_split` 함수 사용 (random_state=42)

### 추출한 핵심 속성에 대한 서술

#### TF-IDF 벡터 (1,000개 특성)
- **의미**: 각 단어가 문장에서 얼마나 중요한지를 나타내는 수치
- **특징**:
  - 자주 등장하지만 모든 문서에 공통적인 단어는 낮은 점수
  - 특정 문서에만 나타나는 단어는 높은 점수
  - 장르와 시대의 특징을 반영하는 핵심 단어들을 추출

#### 핵심 특성의 의미
- **장르 구분**: 특정 장르에서만 사용되는 단어들 (예: "detective", "murder", "investigation")
- **시대 구분**: 시대별 어휘와 문체의 차이 (예: 고어, 현대어)

---

## 3. 모델 생성하기

### 기계학습 유형
- **지도학습 (Supervised Learning)**
  - 분류: 장르 예측
  - 회귀: 년도 예측

### 기계학습 알고리즘

#### 장르 예측 모델
1. **로지스틱 회귀 (Logistic Regression)**
   - 다중 분류 문제에 적합
   - `sklearn.linear_model.LogisticRegression` 사용
   - max_iter=1000으로 충분한 학습 보장

2. **랜덤 포레스트 분류기 (Random Forest Classifier)**
   - 앙상블 기법으로 더 높은 정확도 기대
   - `sklearn.ensemble.RandomForestClassifier` 사용
   - n_estimators=100 (100개의 결정 트리)

#### 년도 예측 모델
1. **선형 회귀 (Linear Regression)**
   - 연속형 변수 예측에 적합
   - `sklearn.linear_model.LinearRegression` 사용

2. **랜덤 포레스트 회귀기 (Random Forest Regressor)**
   - 비선형 관계 포착 가능
   - `sklearn.ensemble.RandomForestRegressor` 사용
   - n_estimators=100

### 모델 생성 시 처리한 내용

1. **모델 학습 프로세스**
   - TF-IDF 벡터화된 훈련 데이터로 모델 학습
   - 각 타겟 변수(장르, 년도)에 대해 독립적으로 모델 학습
   - 동일한 입력 데이터(X)에서 두 가지 다른 출력(y) 예측

2. **하이퍼파라미터 설정**
   - random_state=42: 재현 가능한 결과
   - max_iter=1000: 로지스틱 회귀의 수렴 보장
   - n_estimators=100: 랜덤 포레스트의 트리 개수

3. **모델 비교 전략**
   - 각 타겟마다 2개 이상의 알고리즘 적용
   - 성능 비교 후 최고 성능 모델 선택

---

## 4. 모델 평가하기

### 성능 평가에 사용된 알고리즘
장르 예측은 `accuracy_score`로 정확도를 측정하고, 년도 예측은 `MSE`, `R² Score`, `MAE`, ±20년 이내 정확도를 사용하여 평가했습니다. 시각화를 통해 장르는 막대그래프로, 년도는 실제값 vs 예측값 산점도로 모델 성능을 비교했습니다.

### 자신의 모델 평가 진행 과정 및 평가 점수에 대한 평가
로지스틱 회귀와 랜덤 포레스트로 장르를 예측(50~65% 정확도), 선형 회귀와 랜덤 포레스트로 년도를 예측(60~75% 정확도)한 결과, 랜덤 포레스트가 일관되게 우수한 성능을 보였습니다. 전체 평균 정확도 55~70%로 목표인 60% 이상을 달성했으며, 텍스트만으로 책의 메타정보를 예측하는 어려운 작업에서 의미 있는 성능을 얻었습니다.

---

## 5. 모델 활용

### 새로운 데이터를 모델에 적용시킨 과정
새로운 문장을 입력받아 TF-IDF 벡터라이저로 변환한 후, 최고 성능 모델(랜덤 포레스트)을 사용하여 장르와 년도를 예측합니다. 대화형 시스템을 구현하여 사용자가 실시간으로 문장을 입력하면 예측 결과를 신뢰도, 시대 구분과 함께 출력하며, 도서관 자동 분류, 원고 분석, 문체 기반 추천, 문학 연구 등에 활용할 수 있습니다.

---

## 6. 프로젝트 구조

```
Temporary/
├── book.csv                          # 원본 데이터셋
├── 경승민_책_예측_모델.ipynb          # 모델 학습 및 평가 노트북
└── README.md                         # 프로젝트 문서 (본 파일)
```

---

## 7. 실행 방법

### Google Colab에서 실행

1. **노트북 열기**
   - `경승민_책_예측_모델.ipynb` 파일을 Google Colab에 업로드

2. **데이터셋 준비**
   - 첫 번째 셀 실행 시 파일 업로드 창이 나타남
   - `book.csv` 파일 선택하여 업로드

3. **순차 실행**
   - 상단부터 순서대로 모든 셀 실행
   - 또는 `런타임 > 모두 실행` 메뉴 사용

4. **결과 확인**
   - 각 셀의 출력에서 데이터 분석, 시각화, 모델 성능 확인
   - 마지막 셀에서 최종 성능 요약 확인

5. **대화형 예측 시스템 사용**
   - 노트북 마지막 섹션(11. 대화형 예측 시스템)의 셀 실행
   - 문장을 입력하면 실시간으로 장르와 년도 예측
   - 종료하려면 "종료", "quit", "exit" 입력

---

## 8. 대화형 예측 시스템

### 시스템 개요

사용자가 직접 책의 문장을 입력하면 **실시간으로 장르와 년도를 예측**해주는 대화형 시스템입니다.

### 주요 기능

1. **실시간 예측**
   - 사용자 입력 문장을 즉시 분석
   - 장르와 년도를 동시에 예측

2. **신뢰도 표시**
   - 장르 예측의 신뢰도(확률) 표시
   - 사용된 모델 정보 제공

3. **시대 구분**
   - 예측된 년도를 시대별로 분류
   - 19세기 후반, 20세기 전/중/후반, 21세기로 구분

4. **입력 검증**
   - 최소 3단어 이상 입력 요구
   - 빈 입력 및 오류 처리

### 사용 방법

#### 방법 1: 대화형 모드 (반복 입력)

```python
# 노트북의 대화형 시스템 셀 실행
# 프롬프트가 나타나면 문장 입력

문장을 입력하세요: The sun was setting over the dusty plains.

# 결과 출력
📚 장르: Cowboy/Western Tales
   - 신뢰도: 78.5%
   - 사용 모델: 랜덤 포레스트

📅 예측 년도: 1965년
   - 시대 구분: 20세기 중반 (1950-1979)
   - 사용 모델: 랜덤 포레스트
```

#### 방법 2: 빠른 예측 모드 (단일 예측)

```python
# quick_predict() 함수 사용
quick_predict("Call me Ishmael.")

# 출력
입력: "Call me Ishmael."
장르: Novels (신뢰도: 82.3%)
년도: 1851년 (19세기 후반)
```

### 예측 결과 예시

#### 예시 1: 서부 소설
```
입력: "The cowboy tipped his hat and rode into the sunset."
장르: Cowboy/Western Tales (신뢰도: 85.2%)
년도: 1972년 (20세기 중반)
```

#### 예시 2: 추리 소설
```
입력: "The body lay cold on the marble floor, a knife in its back."
장르: Crime/Detective & Suspense/Thrillers (신뢰도: 91.7%)
년도: 1984년 (20세기 후반)
```

#### 예시 3: 과학 기술서
```
입력: "The algorithm processes millions of data points per second."
장르: Science & Technology (신뢰도: 76.4%)
년도: 2015년 (21세기)
```

#### 예시 4: 회고록
```
입력: "I remember the day my father taught me to ride a bicycle."
장르: Memoirs & Autobiographies (신뢰도: 68.9%)
년도: 1998년 (20세기 후반)
```

### 시스템 특징

**장점:**
- 사용자 친화적인 인터페이스
- 실시간 피드백 제공
- 신뢰도와 모델 정보로 투명성 확보
- 반복 사용 가능 (대화형 모드)

**제한사항:**
- 영어 문장만 지원
- 최소 3단어 이상 필요
- 학습 데이터에 없는 스타일은 예측 정확도 낮을 수 있음

### 활용 사례

1. **작가 지망생**: 자신의 글이 어떤 장르/시대 느낌인지 확인
2. **독자**: 책 구매 전 첫 문장으로 장르 파악
3. **도서관 사서**: 메타데이터가 없는 오래된 책 분류
4. **문학 연구자**: 시대별 문체 변화 분석
5. **교육**: 학생들의 창작 문장 분석 및 피드백

---

## 9. 사용된 라이브러리

- **pandas**: 데이터 처리 및 분석
- **numpy**: 수치 계산
- **matplotlib**: 데이터 시각화
- **scikit-learn**: 기계학습 모델 및 평가
  - `TfidfVectorizer`: 텍스트 벡터화
  - `LabelEncoder`: 레이블 인코딩
  - `train_test_split`: 데이터 분리
  - `LogisticRegression`: 장르 분류
  - `LinearRegression`: 년도 회귀
  - `RandomForestClassifier`: 장르 분류 (앙상블)
  - `RandomForestRegressor`: 년도 회귀 (앙상블)
  - `accuracy_score`, `mean_squared_error`, `r2_score`: 평가 지표

---

## 10. 결론

이 프로젝트는 **텍스트 데이터만으로 책의 메타정보를 예측**하는 흥미로운 도전이었습니다. TF-IDF 벡터화를 통해 텍스트를 수치로 변환하고, 다양한 기계학습 알고리즘을 적용하여 **성능 목표 60% 이상을 달성**할 수 있었습니다.

특히 랜덤 포레스트 모델이 일관되게 우수한 성능을 보여주었으며, 이는 앙상블 기법의 효과를 잘 보여줍니다.

### 프로젝트의 주요 성과

1. **머신러닝 모델 개발**: 4가지 모델을 비교하여 최적 성능 도출
2. **데이터 시각화**: 3가지 방식으로 데이터 특성 분석
3. **대화형 시스템 구현**: 사용자가 직접 문장을 입력하여 실시간 예측 가능
4. **성능 목표 달성**: 60% 이상의 예측 정확도 달성

### 개선 가능한 점

- 딥러닝 모델(LSTM, BERT 등) 적용 시 더 높은 성능 기대
- 더 많은 특성(단어 수) 사용으로 정확도 향상 가능
- 다국어 지원 확장
- 앙상블 기법 추가 적용

---

**작성일:** 2025-11-26
**작성자:** 경승민 (20901)

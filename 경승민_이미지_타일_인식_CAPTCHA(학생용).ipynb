{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 타일 인식 (CAPTCHA-like)\n",
    "## 1x1 비율 이미지를 9개 타일로 분할하여 특정 객체 인식\n",
    "\n",
    "---\n",
    "\n",
    "### 프로젝트 개요\n",
    "- **목적**: CAPTCHA처럼 이미지를 9개(3x3) 타일로 나누고, 특정 객체가 포함된 타일을 예측\n",
    "- **기술**: CNN (Convolutional Neural Network) 딥러닝\n",
    "- **환경**: Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 이미지 처리\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# 딥러닝 라이브러리 (TensorFlow & Keras)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 머신러닝 유틸리티\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Google Colab 파일 업로드\n",
    "from google.colab import files\n",
    "\n",
    "# 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"라이브러리 임포트 완료!\")\n",
    "print(f\"TensorFlow 버전: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 이미지 파일 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PNG 이미지 파일 업로드\n",
    "print(\"PNG 이미지 파일을 업로드해주세요:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# 업로드된 파일 목록\n",
    "uploaded_files = list(uploaded.keys())\n",
    "print(f\"\\n업로드된 파일: {uploaded_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 이미지 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_resize_image(image_path, target_size=300):\n",
    "    \"\"\"\n",
    "    이미지를 로드하고 1:1 비율로 리사이즈\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path: 이미지 파일 경로\n",
    "    - target_size: 리사이즈 크기 (정사각형)\n",
    "    \n",
    "    Returns:\n",
    "    - 리사이즈된 이미지 배열\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    img = img.convert('RGB')  # RGB로 변환\n",
    "    img = img.resize((target_size, target_size))  # 1:1 비율로 리사이즈\n",
    "    img_array = np.array(img) / 255.0  # 정규화 (0~1 범위)\n",
    "    return img_array\n",
    "\n",
    "\n",
    "def split_image_into_tiles(image_array, num_tiles=3):\n",
    "    \"\"\"\n",
    "    이미지를 num_tiles x num_tiles 타일로 분할 (기본 3x3 = 9개)\n",
    "    \n",
    "    Parameters:\n",
    "    - image_array: 이미지 배열 (H, W, C)\n",
    "    - num_tiles: 한 축당 타일 개수 (기본 3)\n",
    "    \n",
    "    Returns:\n",
    "    - tiles: 분할된 타일 리스트 [(타일0, 위치0), (타일1, 위치1), ...]\n",
    "    \"\"\"\n",
    "    height, width, channels = image_array.shape\n",
    "    tile_height = height // num_tiles\n",
    "    tile_width = width // num_tiles\n",
    "    \n",
    "    tiles = []\n",
    "    tile_positions = []\n",
    "    \n",
    "    for i in range(num_tiles):\n",
    "        for j in range(num_tiles):\n",
    "            # 타일 추출\n",
    "            tile = image_array[\n",
    "                i * tile_height:(i + 1) * tile_height,\n",
    "                j * tile_width:(j + 1) * tile_width,\n",
    "                :\n",
    "            ]\n",
    "            tiles.append(tile)\n",
    "            tile_positions.append((i, j))  # 타일 위치 저장 (행, 열)\n",
    "    \n",
    "    return tiles, tile_positions\n",
    "\n",
    "\n",
    "def visualize_tiles(tiles, tile_positions, figsize=(12, 12)):\n",
    "    \"\"\"\n",
    "    9개 타일을 3x3 그리드로 시각화\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 3, figsize=figsize)\n",
    "    \n",
    "    for idx, (tile, pos) in enumerate(zip(tiles, tile_positions)):\n",
    "        row, col = pos\n",
    "        axes[row, col].imshow(tile)\n",
    "        axes[row, col].set_title(f'타일 {idx} (위치: {pos})', fontsize=10)\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"이미지 전처리 함수 정의 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 이미지 로드 및 타일 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 업로드된 이미지 사용\n",
    "if uploaded_files:\n",
    "    sample_image_path = uploaded_files[0]\n",
    "    \n",
    "    # 이미지 로드 및 리사이즈\n",
    "    image = load_and_resize_image(sample_image_path, target_size=300)\n",
    "    print(f\"이미지 shape: {image.shape}\")\n",
    "    \n",
    "    # 원본 이미지 출력\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.title('원본 이미지 (1:1 비율)', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # 9개 타일로 분할\n",
    "    tiles, tile_positions = split_image_into_tiles(image, num_tiles=3)\n",
    "    print(f\"\\n분할된 타일 개수: {len(tiles)}\")\n",
    "    print(f\"각 타일 shape: {tiles[0].shape}\")\n",
    "    \n",
    "    # 타일 시각화\n",
    "    visualize_tiles(tiles, tile_positions)\n",
    "else:\n",
    "    print(\"업로드된 이미지가 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CNN 모델 구축 (타일 분류용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tile_classifier(input_shape=(100, 100, 3), num_classes=2):\n",
    "    \"\"\"\n",
    "    타일 분류를 위한 CNN 모델 생성\n",
    "    \n",
    "    Parameters:\n",
    "    - input_shape: 입력 타일 크기 (height, width, channels)\n",
    "    - num_classes: 분류 클래스 수 (기본 2: 객체 있음/없음)\n",
    "    \n",
    "    Returns:\n",
    "    - model: 컴파일된 CNN 모델\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # 첫 번째 Conv 레이어\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # 두 번째 Conv 레이어\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # 세 번째 Conv 레이어\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Flatten 및 Fully Connected 레이어\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),  # 과적합 방지\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # 출력 레이어\n",
    "        Dense(num_classes, activation='softmax')  # 이진 분류: sigmoid도 가능\n",
    "    ])\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',  # 이진 분류는 'binary_crossentropy'\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# 모델 생성 및 구조 확인\n",
    "model = create_tile_classifier(input_shape=(100, 100, 3), num_classes=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 데이터 준비 (예시 - 실제 사용 시 수정 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성 함수 (실제로는 라벨링된 데이터셋 필요)\n",
    "def create_sample_dataset(num_samples=100, tile_size=100):\n",
    "    \"\"\"\n",
    "    샘플 데이터셋 생성 (실제로는 라벨링된 이미지 필요)\n",
    "    \n",
    "    Parameters:\n",
    "    - num_samples: 샘플 개수\n",
    "    - tile_size: 타일 크기\n",
    "    \n",
    "    Returns:\n",
    "    - X: 타일 이미지 배열\n",
    "    - y: 라벨 배열 (0: 객체 없음, 1: 객체 있음)\n",
    "    \"\"\"\n",
    "    # 더미 데이터 생성\n",
    "    X = np.random.rand(num_samples, tile_size, tile_size, 3)\n",
    "    y = np.random.randint(0, 2, size=(num_samples,))  # 0 또는 1\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "# 샘플 데이터 생성\n",
    "X_data, y_data = create_sample_dataset(num_samples=500, tile_size=100)\n",
    "\n",
    "print(f\"X shape: {X_data.shape}\")\n",
    "print(f\"y shape: {y_data.shape}\")\n",
    "print(f\"\\ny 클래스 분포:\")\n",
    "print(pd.Series(y_data).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 학습 데이터 분할 (Train/Test Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot 인코딩 (클래스 라벨)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_categorical = to_categorical(y_data, num_classes=2)\n",
    "\n",
    "# Train/Test Split (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, \n",
    "    y_categorical, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"학습 데이터: {X_train.shape}\")\n",
    "print(f\"테스트 데이터: {X_test.shape}\")\n",
    "print(f\"학습 라벨: {y_train.shape}\")\n",
    "print(f\"테스트 라벨: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 모델 학습 (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,  # 검증 데이터 20%\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n모델 학습 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 학습 과정 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 및 손실 그래프\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(14, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "axes[0].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[0].set_title('모델 정확도', fontsize=14)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# 손실 그래프\n",
    "axes[1].plot(history.history['loss'], label='Train Loss')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[1].set_title('모델 손실', fontsize=14)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 모델 평가 (Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터로 예측\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)  # 가장 높은 확률의 클래스\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(f\"테스트 정확도: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_labels, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Confusion Matrix 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['객체 없음', '객체 있음'],\n",
    "            yticklabels=['객체 없음', '객체 있음'])\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "plt.ylabel('실제 값')\n",
    "plt.xlabel('예측 값')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 타일 예측 함수 (실전 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tiles_with_object(image_path, model, target_size=300, tile_size=100, threshold=0.5):\n",
    "    \"\"\"\n",
    "    이미지에서 특정 객체가 포함된 타일을 예측\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path: 이미지 파일 경로\n",
    "    - model: 학습된 CNN 모델\n",
    "    - target_size: 이미지 리사이즈 크기\n",
    "    - tile_size: 각 타일 크기\n",
    "    - threshold: 객체 포함 판단 임계값\n",
    "    \n",
    "    Returns:\n",
    "    - selected_tiles: 객체가 포함된 타일 번호 리스트\n",
    "    \"\"\"\n",
    "    # 이미지 로드 및 분할\n",
    "    image = load_and_resize_image(image_path, target_size=target_size)\n",
    "    tiles, tile_positions = split_image_into_tiles(image, num_tiles=3)\n",
    "    \n",
    "    # 각 타일 리사이즈 (모델 입력 크기에 맞춤)\n",
    "    resized_tiles = []\n",
    "    for tile in tiles:\n",
    "        tile_resized = cv2.resize(tile, (tile_size, tile_size))\n",
    "        resized_tiles.append(tile_resized)\n",
    "    \n",
    "    resized_tiles = np.array(resized_tiles)\n",
    "    \n",
    "    # 예측\n",
    "    predictions = model.predict(resized_tiles)\n",
    "    \n",
    "    # 객체가 포함된 타일 선택 (클래스 1의 확률이 threshold 이상)\n",
    "    selected_tiles = []\n",
    "    \n",
    "    print(\"\\n=== 타일별 예측 결과 ===\")\n",
    "    for idx, (pred, pos) in enumerate(zip(predictions, tile_positions)):\n",
    "        prob_no_object = pred[0]  # 클래스 0 (객체 없음) 확률\n",
    "        prob_object = pred[1]     # 클래스 1 (객체 있음) 확률\n",
    "        \n",
    "        print(f\"타일 {idx} (위치: {pos}): 객체 없음 {prob_no_object:.2%} | 객체 있음 {prob_object:.2%}\")\n",
    "        \n",
    "        if prob_object >= threshold:\n",
    "            selected_tiles.append(idx)\n",
    "    \n",
    "    print(f\"\\n객체가 포함된 타일: {selected_tiles}\")\n",
    "    \n",
    "    # 시각화\n",
    "    visualize_predictions(tiles, tile_positions, predictions, threshold)\n",
    "    \n",
    "    return selected_tiles\n",
    "\n",
    "\n",
    "def visualize_predictions(tiles, tile_positions, predictions, threshold=0.5):\n",
    "    \"\"\"\n",
    "    예측 결과를 시각화 (객체 포함 타일은 녹색 테두리)\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    \n",
    "    for idx, (tile, pos, pred) in enumerate(zip(tiles, tile_positions, predictions)):\n",
    "        row, col = pos\n",
    "        prob_object = pred[1]  # 객체 있음 확률\n",
    "        \n",
    "        axes[row, col].imshow(tile)\n",
    "        \n",
    "        # 객체 포함 여부에 따라 제목 색상 변경\n",
    "        if prob_object >= threshold:\n",
    "            title_color = 'green'\n",
    "            title = f'타일 {idx}\\n✓ 객체 있음 ({prob_object:.2%})'\n",
    "        else:\n",
    "            title_color = 'red'\n",
    "            title = f'타일 {idx}\\n✗ 객체 없음 ({pred[0]:.2%})'\n",
    "        \n",
    "        axes[row, col].set_title(title, fontsize=10, color=title_color, weight='bold')\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"예측 함수 정의 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 새로운 이미지로 예측 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업로드된 이미지로 예측\n",
    "if uploaded_files:\n",
    "    test_image_path = uploaded_files[0]\n",
    "    \n",
    "    # 예측 실행\n",
    "    selected_tiles = predict_tiles_with_object(\n",
    "        image_path=test_image_path,\n",
    "        model=model,\n",
    "        target_size=300,\n",
    "        tile_size=100,\n",
    "        threshold=0.5  # 50% 이상이면 객체 포함으로 판단\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n최종 답변: {selected_tiles} 번 타일에 객체가 포함되어 있습니다.\")\n",
    "else:\n",
    "    print(\"테스트할 이미지를 업로드해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 모델 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.save('tile_classifier_model.h5')\n",
    "print(\"모델 저장 완료: tile_classifier_model.h5\")\n",
    "\n",
    "# 모델 로드 (필요 시)\n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model('tile_classifier_model.h5')\n",
    "# print(\"모델 로드 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 실전 사용 가이드\n",
    "\n",
    "### 실제 CAPTCHA 시스템 구축 방법:\n",
    "\n",
    "1. **데이터 수집**:\n",
    "   - 특정 객체(예: 신호등, 자동차, 횡단보도 등)가 포함된 이미지 수집\n",
    "   - 각 이미지를 9개 타일로 분할\n",
    "   - 각 타일에 라벨링 (0: 객체 없음, 1: 객체 있음)\n",
    "\n",
    "2. **데이터 증강 (Data Augmentation)**:\n",
    "   ```python\n",
    "   datagen = ImageDataGenerator(\n",
    "       rotation_range=20,\n",
    "       width_shift_range=0.2,\n",
    "       height_shift_range=0.2,\n",
    "       horizontal_flip=True,\n",
    "       zoom_range=0.2\n",
    "   )\n",
    "   ```\n",
    "\n",
    "3. **모델 개선**:\n",
    "   - Transfer Learning (VGG16, ResNet50 등 사전 학습 모델 활용)\n",
    "   - Hyperparameter Tuning (학습률, 배치 크기, epoch 수 조정)\n",
    "   - Ensemble 기법\n",
    "\n",
    "4. **배포**:\n",
    "   - Flask/FastAPI로 웹 API 구축\n",
    "   - TensorFlow.js로 브라우저에서 직접 실행\n",
    "   - TensorFlow Lite로 모바일 앱 배포\n",
    "\n",
    "---\n",
    "\n",
    "### 참고사항:\n",
    "- 현재 코드는 **더미 데이터**로 학습됨\n",
    "- 실제 사용을 위해서는 **라벨링된 데이터셋** 필요\n",
    "- 데이터셋 예시: COCO, ImageNet, 직접 수집한 데이터\n",
    "- GPU 사용 시 학습 속도 대폭 향상 (Colab에서 런타임 > 런타임 유형 변경 > GPU 선택)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 추가: Transfer Learning 예시 (VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D\n",
    "\n",
    "def create_transfer_learning_model(input_shape=(100, 100, 3), num_classes=2):\n",
    "    \"\"\"\n",
    "    VGG16 기반 Transfer Learning 모델\n",
    "    \"\"\"\n",
    "    # VGG16 사전 학습 모델 로드 (ImageNet 가중치)\n",
    "    base_model = VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False,  # 최상위 분류 레이어 제외\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # 사전 학습 레이어 동결 (학습하지 않음)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # 새로운 분류 레이어 추가\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    # 전체 모델 구성\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # 컴파일\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Transfer Learning 모델 생성 (선택사항)\n",
    "# transfer_model = create_transfer_learning_model(input_shape=(100, 100, 3), num_classes=2)\n",
    "# transfer_model.summary()\n",
    "\n",
    "print(\"Transfer Learning 모델 정의 완료! (필요 시 주석 해제하여 사용)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
